{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-05T15:37:15.548387Z",
     "start_time": "2025-04-05T15:37:12.147532Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "sns.set(font_scale=1.2)\n",
    "\n",
    "# Define the data directory\n",
    "data_dir = './nortwind'\n",
    "\n",
    "# Function to read all CSV files\n",
    "def read_csv_files(directory):\n",
    "    dataframes = {}\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(directory, file)\n",
    "            file_name = os.path.splitext(file)[0]\n",
    "            try:\n",
    "                df = pd.read_csv(file_path)\n",
    "                dataframes[file_name] = df\n",
    "                print(f\"Loaded {file_name} with {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {file}: {e}\")\n",
    "    return dataframes\n",
    "\n",
    "# Load all CSV files\n",
    "dfs = read_csv_files(data_dir)\n",
    "\n",
    "# Basic exploration of each dataframe\n",
    "def explore_dataframes(dataframes):\n",
    "    for name, df in dataframes.items():\n",
    "        print(f\"\\n=== {name} ===\")\n",
    "        print(f\"Shape: {df.shape}\")\n",
    "        print(\"Columns:\")\n",
    "        for col in df.columns:\n",
    "            print(f\"  - {col}: {df[col].dtype}\")\n",
    "        print(\"Sample data:\")\n",
    "        print(df.head(3))\n",
    "        print(\"=\"*50)\n",
    "\n",
    "# Perform exploratory analysis\n",
    "explore_dataframes(dfs)\n",
    "\n",
    "# Sales Analysis\n",
    "def analyze_sales(orders_df, order_details_df, products_df, customers_df):\n",
    "    # Merge order details with products to get prices\n",
    "    order_analysis = pd.merge(order_details_df, products_df,\n",
    "                             on='product_id', how='left')\n",
    "\n",
    "    # Calculate sales amount per order detail\n",
    "    order_analysis['sales_amount'] = order_analysis['quantity'] * order_analysis['unit_price_x'] * (1 - order_analysis['discount'])\n",
    "\n",
    "    # Aggregate sales by order\n",
    "    order_sales = order_analysis.groupby('order_id')['sales_amount'].sum().reset_index()\n",
    "\n",
    "    # Merge with orders table to get order dates and customer info\n",
    "    order_sales = pd.merge(order_sales, orders_df, on='order_id', how='left')\n",
    "\n",
    "    # Convert order date to datetime if it's not already\n",
    "    order_sales['order_date'] = pd.to_datetime(order_sales['order_date'])\n",
    "\n",
    "    # Extract month and year for time analysis\n",
    "    order_sales['month'] = order_sales['order_date'].dt.month\n",
    "    order_sales['year'] = order_sales['order_date'].dt.year\n",
    "    order_sales['month_year'] = order_sales['order_date'].dt.to_period('M')\n",
    "\n",
    "    # Merge with customers to get customer demographics\n",
    "    sales_with_customers = pd.merge(order_sales, customers_df,\n",
    "                                   on='customer_id', how='left')\n",
    "\n",
    "    return order_analysis, order_sales, sales_with_customers\n",
    "\n",
    "# Product Analysis\n",
    "def analyze_products(order_details_df, products_df):\n",
    "    # Merge order details with products\n",
    "    product_sales = pd.merge(order_details_df, products_df,\n",
    "                            on='product_id', how='left')\n",
    "\n",
    "    # Calculate total quantity and revenue per product\n",
    "    product_metrics = product_sales.groupby('product_id').agg(\n",
    "        total_quantity=('quantity', 'sum'),\n",
    "        total_revenue=lambda x: (x['quantity'] * x['unit_price_x'] * (1 - x['discount'])).sum(),\n",
    "        avg_discount=('discount', 'mean')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Merge with product info\n",
    "    product_metrics = pd.merge(product_metrics, products_df[['product_id', 'product_name', 'category_id', 'supplier_id']],\n",
    "                              on='product_id', how='left')\n",
    "\n",
    "    return product_metrics\n",
    "\n",
    "# Customer Analysis\n",
    "def analyze_customers(orders_df, order_sales_df, customers_df):\n",
    "    # Merge sales data with customers\n",
    "    customer_sales = pd.merge(order_sales_df, customers_df,\n",
    "                             on='customer_id', how='left')\n",
    "\n",
    "    # Calculate metrics per customer\n",
    "    customer_metrics = customer_sales.groupby('customer_id').agg(\n",
    "        total_orders=('order_id', 'nunique'),\n",
    "        total_revenue=('sales_amount', 'sum'),\n",
    "        avg_order_value=('sales_amount', 'mean'),\n",
    "        first_order=('order_date', 'min'),\n",
    "        last_order=('order_date', 'max')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Calculate days since last order (potential churn indicator)\n",
    "    latest_date = orders_df['order_date'].max()\n",
    "    customer_metrics['days_since_last_order'] = (pd.to_datetime(latest_date) - customer_metrics['last_order']).dt.days\n",
    "\n",
    "    # Calculate customer lifetime\n",
    "    customer_metrics['customer_lifetime_days'] = (customer_metrics['last_order'] - customer_metrics['first_order']).dt.days\n",
    "\n",
    "    # Merge with customer info\n",
    "    customer_metrics = pd.merge(customer_metrics,\n",
    "                               customers_df[['customer_id', 'company_name', 'country', 'region', 'city']],\n",
    "                               on='customer_id', how='left')\n",
    "\n",
    "    return customer_metrics\n",
    "\n",
    "# Geographic Analysis\n",
    "def analyze_geography(customer_metrics):\n",
    "    # Sales by country\n",
    "    country_sales = customer_metrics.groupby('country').agg(\n",
    "        total_revenue=('total_revenue', 'sum'),\n",
    "        customer_count=('customer_id', 'nunique'),\n",
    "        avg_revenue_per_customer=('total_revenue', 'mean')\n",
    "    ).reset_index().sort_values(by='total_revenue', ascending=False)\n",
    "\n",
    "    return country_sales\n",
    "\n",
    "# Time Series Analysis\n",
    "def analyze_time_series(order_sales_df):\n",
    "    # Monthly sales trends\n",
    "    monthly_sales = order_sales_df.groupby('month_year')['sales_amount'].sum()\n",
    "\n",
    "    # Convert Period index to datetime for better plotting\n",
    "    monthly_sales.index = monthly_sales.index.to_timestamp()\n",
    "\n",
    "    return monthly_sales\n",
    "\n",
    "# Calculate key performance indicators\n",
    "def calculate_kpis(order_sales_df, customer_metrics):\n",
    "    # Total Revenue\n",
    "    total_revenue = order_sales_df['sales_amount'].sum()\n",
    "\n",
    "    # Average Order Value\n",
    "    avg_order_value = order_sales_df['sales_amount'].mean()\n",
    "\n",
    "    # Number of Unique Customers\n",
    "    unique_customers = customer_metrics['customer_id'].nunique()\n",
    "\n",
    "    # Customer Lifetime Value\n",
    "    clv = total_revenue / unique_customers\n",
    "\n",
    "    # Potentially churned customers (no orders in last 90 days)\n",
    "    potential_churn = customer_metrics[customer_metrics['days_since_last_order'] > 90]['customer_id'].count()\n",
    "    churn_rate = potential_churn / unique_customers\n",
    "\n",
    "    # Customer acquisition over time (by first order date)\n",
    "    customer_acquisition = customer_metrics.groupby(customer_metrics['first_order'].dt.to_period('M')).size()\n",
    "\n",
    "    return {\n",
    "        'total_revenue': total_revenue,\n",
    "        'avg_order_value': avg_order_value,\n",
    "        'unique_customers': unique_customers,\n",
    "        'customer_lifetime_value': clv,\n",
    "        'potential_churn': potential_churn,\n",
    "        'churn_rate': churn_rate,\n",
    "        'customer_acquisition': customer_acquisition\n",
    "    }\n",
    "\n",
    "# Create visualizations\n",
    "def create_visualizations(monthly_sales, product_metrics, country_sales, customer_metrics):\n",
    "    # Set up figure size for the plots\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Plot 1: Monthly Sales Trend\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(monthly_sales.index, monthly_sales.values, marker='o', linestyle='-')\n",
    "    plt.title('Monthly Sales Trend')\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Revenue')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Plot 2: Top 10 Products by Revenue\n",
    "    plt.subplot(2, 2, 2)\n",
    "    top_products = product_metrics.sort_values('total_revenue', ascending=False).head(10)\n",
    "    sns.barplot(x='total_revenue', y='product_name', data=top_products)\n",
    "    plt.title('Top 10 Products by Revenue')\n",
    "    plt.xlabel('Revenue')\n",
    "    plt.ylabel('Product')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Plot 3: Sales by Country\n",
    "    plt.subplot(2, 2, 3)\n",
    "    top_countries = country_sales.head(10)\n",
    "    sns.barplot(x='total_revenue', y='country', data=top_countries)\n",
    "    plt.title('Sales by Country')\n",
    "    plt.xlabel('Revenue')\n",
    "    plt.ylabel('Country')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Plot 4: Customer Recency vs Frequency (Potential Churn Analysis)\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.scatter(customer_metrics['days_since_last_order'],\n",
    "                customer_metrics['total_orders'],\n",
    "                alpha=0.6)\n",
    "    plt.title('Customer Recency vs Frequency')\n",
    "    plt.xlabel('Days Since Last Order')\n",
    "    plt.ylabel('Number of Orders')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig('northwind_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Additional plot: Average Order Value over time\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    order_sales_df['month_year_dt'] = order_sales_df['month_year'].dt.to_timestamp()\n",
    "    monthly_aov = order_sales_df.groupby('month_year_dt')['sales_amount'].mean()\n",
    "    plt.plot(monthly_aov.index, monthly_aov.values, marker='o', linestyle='-', color='green')\n",
    "    plt.title('Average Order Value Over Time')\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Average Order Value')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('northwind_aov_trend.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# For the purposes of this challenge, let's try to run the analyses with the expected dataframe names\n",
    "# Note: These might need adjustment based on the actual CSV file structures\n",
    "try:\n",
    "    # Analyze sales data\n",
    "    order_analysis, order_sales, sales_with_customers = analyze_sales(\n",
    "        dfs.get('orders'), dfs.get('order_details'), dfs.get('products'), dfs.get('customers')\n",
    "    )\n",
    "\n",
    "    # Analyze product data\n",
    "    product_metrics = analyze_products(dfs.get('order_details'), dfs.get('products'))\n",
    "\n",
    "    # Analyze customer data\n",
    "    customer_metrics = analyze_customers(dfs.get('orders'), order_sales, dfs.get('customers'))\n",
    "\n",
    "    # Geographic analysis\n",
    "    country_sales = analyze_geography(customer_metrics)\n",
    "\n",
    "    # Time series analysis\n",
    "    monthly_sales = analyze_time_series(order_sales)\n",
    "\n",
    "    # Calculate KPIs\n",
    "    kpis = calculate_kpis(order_sales, customer_metrics)\n",
    "\n",
    "    # Create visualizations\n",
    "    create_visualizations(monthly_sales, product_metrics, country_sales, customer_metrics)\n",
    "\n",
    "    # Print key insights\n",
    "    print(\"\\n=== KEY INSIGHTS ===\")\n",
    "    print(f\"Total Revenue: ${kpis['total_revenue']:,.2f}\")\n",
    "    print(f\"Average Order Value: ${kpis['avg_order_value']:,.2f}\")\n",
    "    print(f\"Customer Lifetime Value: ${kpis['customer_lifetime_value']:,.2f}\")\n",
    "    print(f\"Potential Churn Rate: {kpis['churn_rate']*100:.2f}%\")\n",
    "\n",
    "    # Export key dataframes to CSV for further analysis\n",
    "    order_sales.to_csv('order_sales_analysis.csv', index=False)\n",
    "    product_metrics.to_csv('product_metrics.csv', index=False)\n",
    "    customer_metrics.to_csv('customer_metrics.csv', index=False)\n",
    "    country_sales.to_csv('country_sales.csv', index=False)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in analysis: {e}\")"
   ],
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "'seaborn-whitegrid' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\flashlight-analise-dados\\.venv\\Lib\\site-packages\\matplotlib\\style\\core.py:129\u001B[39m, in \u001B[36muse\u001B[39m\u001B[34m(style)\u001B[39m\n\u001B[32m    128\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m129\u001B[39m     style = \u001B[43m_rc_params_in_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstyle\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    130\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\flashlight-analise-dados\\.venv\\Lib\\site-packages\\matplotlib\\__init__.py:903\u001B[39m, in \u001B[36m_rc_params_in_file\u001B[39m\u001B[34m(fname, transform, fail_on_error)\u001B[39m\n\u001B[32m    902\u001B[39m rc_temp = {}\n\u001B[32m--> \u001B[39m\u001B[32m903\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mwith\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m_open_file_or_url\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mas\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mfd\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    904\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mtry\u001B[39;49;00m\u001B[43m:\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py:141\u001B[39m, in \u001B[36m_GeneratorContextManager.__enter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    140\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m141\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgen\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    142\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\flashlight-analise-dados\\.venv\\Lib\\site-packages\\matplotlib\\__init__.py:880\u001B[39m, in \u001B[36m_open_file_or_url\u001B[39m\u001B[34m(fname)\u001B[39m\n\u001B[32m    879\u001B[39m fname = os.path.expanduser(fname)\n\u001B[32m--> \u001B[39m\u001B[32m880\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mutf-8\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[32m    881\u001B[39m     \u001B[38;5;28;01myield\u001B[39;00m f\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: 'seaborn-whitegrid'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mOSError\u001B[39m                                   Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 9\u001B[39m\n\u001B[32m      6\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mos\u001B[39;00m\n\u001B[32m      8\u001B[39m \u001B[38;5;66;03m# Set plotting style\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m \u001B[43mplt\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstyle\u001B[49m\u001B[43m.\u001B[49m\u001B[43muse\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mseaborn-whitegrid\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     10\u001B[39m sns.set(font_scale=\u001B[32m1.2\u001B[39m)\n\u001B[32m     12\u001B[39m \u001B[38;5;66;03m# Define the data directory\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\flashlight-analise-dados\\.venv\\Lib\\site-packages\\matplotlib\\style\\core.py:131\u001B[39m, in \u001B[36muse\u001B[39m\u001B[34m(style)\u001B[39m\n\u001B[32m    129\u001B[39m         style = _rc_params_in_file(style)\n\u001B[32m    130\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[32m--> \u001B[39m\u001B[32m131\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(\n\u001B[32m    132\u001B[39m             \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstyle\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[33m is not a valid package style, path of style \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    133\u001B[39m             \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mfile, URL of style file, or library style name (library \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    134\u001B[39m             \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mstyles are listed in `style.available`)\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01merr\u001B[39;00m\n\u001B[32m    135\u001B[39m filtered = {}\n\u001B[32m    136\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m style:  \u001B[38;5;66;03m# don't trigger RcParams.__getitem__('backend')\u001B[39;00m\n",
      "\u001B[31mOSError\u001B[39m: 'seaborn-whitegrid' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d6873b93de201d19"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
