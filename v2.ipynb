{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Northwind Traders - Data Analysis Challenge\n",
    "#\n",
    "# This notebook analyzes the Northwind database to identify key performance indicators and generate insights to help increase average ticket size and reduce customer churn.\n",
    "\n",
    "# ## 1. Setup and Data Loading\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Define file paths\n",
    "base_path = \"./northwind/\"\n",
    "\n",
    "# Load all CSV files\n",
    "categories = pd.read_csv(f'{base_path}categories.csv')\n",
    "customers = pd.read_csv(f'{base_path}customers.csv')\n",
    "customer_demographics = pd.read_csv(f'{base_path}customer_demographics.csv')\n",
    "customer_customer_demo = pd.read_csv(f'{base_path}customer_customer_demo.csv')\n",
    "employees = pd.read_csv(f'{base_path}employees.csv')\n",
    "employee_territories = pd.read_csv(f'{base_path}employee_territories.csv')\n",
    "orders = pd.read_csv(f'{base_path}orders.csv')\n",
    "order_details = pd.read_csv(f'{base_path}order_details.csv')\n",
    "products = pd.read_csv(f'{base_path}products.csv')\n",
    "region = pd.read_csv(f'{base_path}region.csv')\n",
    "shippers = pd.read_csv(f'{base_path}shippers.csv')\n",
    "suppliers = pd.read_csv(f'{base_path}suppliers.csv')\n",
    "territories = pd.read_csv(f'{base_path}territories.csv')\n",
    "us_states = pd.read_csv(f'{base_path}us_states.csv')\n",
    "\n",
    "# Quick look at what we're working with\n",
    "print(\"Datasets overview:\")\n",
    "for name, df in [\n",
    "    (\"categories\", categories),\n",
    "    (\"customers\", customers),\n",
    "    (\"customer_demographics\", customer_demographics),\n",
    "    (\"customer_customer_demo\", customer_customer_demo),\n",
    "    (\"employees\", employees),\n",
    "    (\"employee_territories\", employee_territories),\n",
    "    (\"orders\", orders),\n",
    "    (\"order_details\", order_details),\n",
    "    (\"products\", products),\n",
    "    (\"region\", region),\n",
    "    (\"shippers\", shippers),\n",
    "    (\"suppliers\", suppliers),\n",
    "    (\"territories\", territories),\n",
    "    (\"us_states\", us_states)\n",
    "]:\n",
    "    print(f\"\\n{name}: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "    print(df.columns.tolist())\n",
    "\n",
    "# ## 2. Data Cleaning and Preparation\n",
    "\n",
    "# Convert date columns to datetime in orders\n",
    "orders['order_date'] = pd.to_datetime(orders['order_date'], errors='coerce')\n",
    "orders['required_date'] = pd.to_datetime(orders['required_date'], errors='coerce')\n",
    "orders['shipped_date'] = pd.to_datetime(orders['shipped_date'], errors='coerce')\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in orders:\")\n",
    "print(orders.isnull().sum())\n",
    "\n",
    "# Fill missing shipped_date with appropriate values or mark as not shipped\n",
    "orders['is_shipped'] = ~orders['shipped_date'].isna()\n",
    "\n",
    "# Calculate order_value in order_details\n",
    "order_details['order_value'] = order_details['unit_price'] * order_details['quantity'] * (1 - order_details['discount'])\n",
    "\n",
    "# Merge orders and order_details for analysis\n",
    "orders_with_details = pd.merge(\n",
    "    orders,\n",
    "    order_details.groupby('order_id').agg(\n",
    "        total_amount=('order_value', 'sum'),\n",
    "        unique_products=('product_id', 'nunique'),\n",
    "        total_quantity=('quantity', 'sum')\n",
    "    ).reset_index(),\n",
    "    on='order_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Merge with customers\n",
    "orders_with_customers = pd.merge(\n",
    "    orders_with_details,\n",
    "    customers[['customer_id', 'company_name', 'country', 'region', 'city']],\n",
    "    on='customer_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# ## 3. Analysis Part 1: Revenue and Sales Performance\n",
    "\n",
    "# ### 3.1 Revenue Analysis\n",
    "\n",
    "# Calculate monthly revenue\n",
    "monthly_revenue = orders_with_customers.copy()\n",
    "monthly_revenue['year_month'] = monthly_revenue['order_date'].dt.strftime('%Y-%m')\n",
    "monthly_sales = monthly_revenue.groupby('year_month').agg(\n",
    "    total_revenue=('total_amount', 'sum'),\n",
    "    order_count=('order_id', 'nunique'),\n",
    "    avg_order_value=('total_amount', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Sorting by date\n",
    "monthly_sales['year_month'] = pd.to_datetime(monthly_sales['year_month'] + '-01')\n",
    "monthly_sales = monthly_sales.sort_values('year_month')\n",
    "monthly_sales['year_month'] = monthly_sales['year_month'].dt.strftime('%Y-%m')\n",
    "\n",
    "# Plot monthly sales trends\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(monthly_sales['year_month'], monthly_sales['total_revenue'], marker='o', linewidth=2)\n",
    "plt.title('Monthly Revenue Trend', fontsize=16)\n",
    "plt.xlabel('Month', fontsize=12)\n",
    "plt.ylabel('Revenue', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('monthly_revenue_trend.png')\n",
    "plt.close()\n",
    "\n",
    "# ### 3.2 Average Ticket Size Analysis\n",
    "\n",
    "# Calculate average ticket size by customer segment\n",
    "avg_ticket_by_country = orders_with_customers.groupby('country').agg(\n",
    "    avg_ticket=('total_amount', 'mean'),\n",
    "    order_count=('order_id', 'count'),\n",
    "    total_revenue=('total_amount', 'sum')\n",
    ").reset_index().sort_values('avg_ticket', ascending=False)\n",
    "\n",
    "# Plot top 10 countries by average ticket\n",
    "top_countries = avg_ticket_by_country.nlargest(10, 'avg_ticket')\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='country', y='avg_ticket', data=top_countries)\n",
    "plt.title('Top 10 Countries by Average Ticket Size', fontsize=16)\n",
    "plt.xlabel('Country', fontsize=12)\n",
    "plt.ylabel('Average Ticket ($)', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('top_countries_avg_ticket.png')\n",
    "plt.close()\n",
    "\n",
    "# Calculate average items per order\n",
    "avg_items_per_order = orders_with_details['unique_products'].mean()\n",
    "print(f\"\\nAverage unique products per order: {avg_items_per_order:.2f}\")\n",
    "\n",
    "# ## 4. Analysis Part 2: Customer Behavior and Churn Risk\n",
    "\n",
    "# ### 4.1 Customer Frequency and Recency Analysis\n",
    "\n",
    "# Calculate frequency and recency for each customer\n",
    "customer_frequency = orders.groupby('customer_id').agg(\n",
    "    order_count=('order_id', 'nunique'),\n",
    "    last_order_date=('order_date', 'max'),\n",
    "    first_order_date=('order_date', 'min')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate recency (days since last order)\n",
    "max_date = orders['order_date'].max()\n",
    "customer_frequency['recency_days'] = (max_date - customer_frequency['last_order_date']).dt.days\n",
    "customer_frequency['customer_tenure_days'] = (customer_frequency['last_order_date'] - customer_frequency['first_order_date']).dt.days\n",
    "\n",
    "# Merge with customer info\n",
    "customer_analysis = pd.merge(\n",
    "    customer_frequency,\n",
    "    customers[['customer_id', 'company_name', 'country']],\n",
    "    on='customer_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Define churn risk (customers with no orders in the last 90 days)\n",
    "customer_analysis['churn_risk'] = customer_analysis['recency_days'] > 90\n",
    "\n",
    "# Calculate churn rate\n",
    "churn_rate = customer_analysis['churn_risk'].mean() * 100\n",
    "print(f\"\\nCustomer churn risk rate: {churn_rate:.2f}%\")\n",
    "\n",
    "# Calculate average order value by customer\n",
    "customer_order_value = pd.merge(\n",
    "    orders_with_details.groupby('customer_id').agg(\n",
    "        avg_order_value=('total_amount', 'mean'),\n",
    "        total_spent=('total_amount', 'sum')\n",
    "    ).reset_index(),\n",
    "    customer_analysis[['customer_id', 'order_count', 'recency_days', 'churn_risk']],\n",
    "    on='customer_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Identify high-value customers at risk of churning\n",
    "high_value_churn = customer_order_value[\n",
    "    (customer_order_value['avg_order_value'] > customer_order_value['avg_order_value'].median()) &\n",
    "    (customer_order_value['churn_risk'])\n",
    "].sort_values('total_spent', ascending=False)\n",
    "\n",
    "print(f\"\\nHigh-value customers at risk of churning: {len(high_value_churn)}\")\n",
    "\n",
    "# ## 5. Analysis Part 3: Product Performance\n",
    "\n",
    "# ### 5.1 Top Performing Products\n",
    "\n",
    "# Analyze product performance\n",
    "product_performance = pd.merge(\n",
    "    order_details.groupby('product_id').agg(\n",
    "        total_revenue=('order_value', 'sum'),\n",
    "        order_count=('order_id', 'nunique'),\n",
    "        total_quantity=('quantity', 'sum')\n",
    "    ).reset_index(),\n",
    "    products[['product_id', 'product_name', 'category_id', 'unit_price']],\n",
    "    on='product_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Add category names\n",
    "product_performance = pd.merge(\n",
    "    product_performance,\n",
    "    categories[['category_id', 'category_name']],\n",
    "    on='category_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Sort by revenue\n",
    "product_performance = product_performance.sort_values('total_revenue', ascending=False)\n",
    "\n",
    "# Top 10 products by revenue\n",
    "top_products = product_performance.head(10)\n",
    "print(\"\\nTop 10 Products by Revenue:\")\n",
    "print(top_products[['product_name', 'total_revenue', 'order_count', 'total_quantity']])\n",
    "\n",
    "# Product category analysis\n",
    "category_performance = product_performance.groupby('category_name').agg(\n",
    "    total_revenue=('total_revenue', 'sum'),\n",
    "    product_count=('product_id', 'nunique'),\n",
    "    avg_price=('unit_price', 'mean')\n",
    ").reset_index().sort_values('total_revenue', ascending=False)\n",
    "\n",
    "# Plot category performance\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='category_name', y='total_revenue', data=category_performance)\n",
    "plt.title('Revenue by Product Category', fontsize=16)\n",
    "plt.xlabel('Category', fontsize=12)\n",
    "plt.ylabel('Total Revenue ($)', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('category_revenue.png')\n",
    "plt.close()\n",
    "\n",
    "# ## 6. Cross-Selling and Basket Analysis\n",
    "\n",
    "# Identify products frequently purchased together\n",
    "# First, get all order-product combinations\n",
    "order_products = order_details[['order_id', 'product_id']].copy()\n",
    "order_products = pd.merge(\n",
    "    order_products,\n",
    "    products[['product_id', 'product_name']],\n",
    "    on='product_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Create a product pairs table\n",
    "def get_product_pairs(order_id):\n",
    "    prods = order_products[order_products['order_id'] == order_id]['product_name'].tolist()\n",
    "    pairs = []\n",
    "    for i in range(len(prods)):\n",
    "        for j in range(i+1, len(prods)):\n",
    "            # Ensure alphabetical sorting for consistent pairs\n",
    "            if prods[i] < prods[j]:\n",
    "                pairs.append((prods[i], prods[j]))\n",
    "            else:\n",
    "                pairs.append((prods[j], prods[i]))\n",
    "    return pairs\n",
    "\n",
    "# Get orders with multiple products\n",
    "orders_with_multiple = orders_with_details[orders_with_details['unique_products'] > 1]['order_id'].unique()\n",
    "\n",
    "# For efficiency, limit to a subset of orders for this analysis\n",
    "if len(orders_with_multiple) > 100:\n",
    "    sample_orders = np.random.choice(orders_with_multiple, 100, replace=False)\n",
    "else:\n",
    "    sample_orders = orders_with_multiple\n",
    "\n",
    "# Generate all pairs from sample orders\n",
    "all_pairs = []\n",
    "for order_id in sample_orders:\n",
    "    all_pairs.extend(get_product_pairs(order_id))\n",
    "\n",
    "# Count frequencies\n",
    "pair_counts = {}\n",
    "for pair in all_pairs:\n",
    "    if pair in pair_counts:\n",
    "        pair_counts[pair] += 1\n",
    "    else:\n",
    "        pair_counts[pair] = 1\n",
    "\n",
    "# Convert to dataframe and sort\n",
    "pairs_df = pd.DataFrame([(p[0], p[1], c) for p, c in pair_counts.items()],\n",
    "                       columns=['product1', 'product2', 'frequency'])\n",
    "pairs_df = pairs_df.sort_values('frequency', ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 Product Pairs Frequently Purchased Together:\")\n",
    "print(pairs_df.head(5))\n",
    "\n",
    "# ## 7. Key Insights and Recommendations\n",
    "\n",
    "# ### 7.1 Average Ticket Size Enhancement\n",
    "\n",
    "# Analyze impact of product variety on order value\n",
    "order_details_with_info = pd.merge(\n",
    "    order_details,\n",
    "    products[['product_id', 'product_name', 'category_id']],\n",
    "    on='product_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "order_details_with_info = pd.merge(\n",
    "    order_details_with_info,\n",
    "    categories[['category_id', 'category_name']],\n",
    "    on='category_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Calculate product and category diversity per order\n",
    "order_diversity = order_details_with_info.groupby('order_id').agg(\n",
    "    product_count=('product_id', 'nunique'),\n",
    "    category_count=('category_id', 'nunique'),\n",
    "    order_value=('order_value', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Analyze relationship between product diversity and order value\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='product_count', y='order_value', data=order_diversity)\n",
    "plt.title('Relationship Between Product Diversity and Order Value', fontsize=16)\n",
    "plt.xlabel('Number of Unique Products in Order', fontsize=12)\n",
    "plt.ylabel('Total Order Value ($)', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('product_diversity_order_value.png')\n",
    "plt.close()\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = order_diversity['product_count'].corr(order_diversity['order_value'])\n",
    "print(f\"\\nCorrelation between product count and order value: {correlation:.4f}\")\n",
    "\n",
    "# ### 7.2 Churn Reduction Strategies\n",
    "\n",
    "# Identify patterns in customer behavior before churn\n",
    "# First, calculate time between orders for each customer\n",
    "customer_orders = orders[['customer_id', 'order_id', 'order_date']].sort_values(['customer_id', 'order_date'])\n",
    "customer_orders['prev_order_date'] = customer_orders.groupby('customer_id')['order_date'].shift(1)\n",
    "customer_orders['days_since_prev_order'] = (customer_orders['order_date'] - customer_orders['prev_order_date']).dt.days\n",
    "\n",
    "# Filter out first orders (where prev_order_date is NaN)\n",
    "customer_orders = customer_orders.dropna(subset=['prev_order_date'])\n",
    "\n",
    "# Compare active vs churned customers\n",
    "active_customers = customer_analysis[~customer_analysis['churn_risk']]['customer_id'].tolist()\n",
    "churned_customers = customer_analysis[customer_analysis['churn_risk']]['customer_id'].tolist()\n",
    "\n",
    "active_order_gaps = customer_orders[customer_orders['customer_id'].isin(active_customers)]['days_since_prev_order']\n",
    "churned_order_gaps = customer_orders[customer_orders['customer_id'].isin(churned_customers)]['days_since_prev_order']\n",
    "\n",
    "# Calculate average time between orders\n",
    "if len(active_order_gaps) > 0 and len(churned_order_gaps) > 0:\n",
    "    print(f\"\\nAvg days between orders (active customers): {active_order_gaps.mean():.2f}\")\n",
    "    print(f\"Avg days between orders (churned customers): {churned_order_gaps.mean():.2f}\")\n",
    "\n",
    "# ## 8. Executive Summary\n",
    "\n",
    "# Calculate key metrics for executive summary\n",
    "total_revenue = orders_with_details['total_amount'].sum()\n",
    "total_orders = len(orders_with_details)\n",
    "avg_order_value = total_revenue / total_orders if total_orders > 0 else 0\n",
    "total_customers = len(customers)\n",
    "repeat_customers = customer_analysis[customer_analysis['order_count'] > 1].shape[0]\n",
    "repeat_rate = repeat_customers / total_customers * 100\n",
    "\n",
    "print(\"\\n*** EXECUTIVE SUMMARY ***\")\n",
    "print(f\"Total Revenue: ${total_revenue:,.2f}\")\n",
    "print(f\"Total Orders: {total_orders}\")\n",
    "print(f\"Average Order Value: ${avg_order_value:,.2f}\")\n",
    "print(f\"Total Customers: {total_customers}\")\n",
    "print(f\"Repeat Purchase Rate: {repeat_rate:.2f}%\")\n",
    "print(f\"Customer Churn Risk Rate: {churn_rate:.2f}%\")\n",
    "\n",
    "# Create recommendations based on analysis\n",
    "print(\"\\n*** KEY RECOMMENDATIONS ***\")\n",
    "print(\"1. Implement cross-selling strategies for top product pairs to increase average ticket size\")\n",
    "print(\"2. Develop a customer retention program targeting high-value customers with high churn risk\")\n",
    "print(\"3. Expand product categories with highest average order values to improve overall revenue\")\n",
    "print(\"4. Create a loyalty program to reduce time between orders for customers showing signs of disengagement\")\n",
    "print(\"5. Implement personalized marketing campaigns based on purchase history and category preferences\")\n",
    "\n",
    "# ## 9. Data Visualization Dashboard Preparation\n",
    "\n",
    "# Prepare data for dashboard visualizations\n",
    "# Monthly sales trend\n",
    "monthly_trend = orders.copy()\n",
    "monthly_trend['year_month'] = monthly_trend['order_date'].dt.strftime('%Y-%m')\n",
    "monthly_trend = pd.merge(\n",
    "    monthly_trend,\n",
    "    order_details.groupby('order_id')['order_value'].sum().reset_index(),\n",
    "    on='order_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "monthly_summary = monthly_trend.groupby('year_month').agg(\n",
    "    total_revenue=('order_value', 'sum'),\n",
    "    order_count=('order_id', 'nunique'),\n",
    "    customer_count=('customer_id', 'nunique')\n",
    ").reset_index()\n",
    "\n",
    "# Save processed data for potential dashboard use\n",
    "monthly_summary.to_csv('monthly_sales_summary.csv', index=False)\n",
    "category_performance.to_csv('category_performance.csv', index=False)\n",
    "top_products.to_csv('top_products.csv', index=False)\n",
    "high_value_churn.to_csv('high_value_churn_risk.csv', index=False)\n",
    "\n",
    "# Calculate customer segmentation for targeting\n",
    "customer_segments = customer_order_value.copy()\n",
    "customer_segments['recency_segment'] = pd.qcut(customer_segments['recency_days'], 3, labels=['Recent', 'Moderate', 'Distant'])\n",
    "customer_segments['frequency_segment'] = pd.qcut(customer_segments['order_count'], 3, labels=['Low', 'Medium', 'High'])\n",
    "customer_segments['monetary_segment'] = pd.qcut(customer_segments['total_spent'], 3, labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "# Combine into RFM score\n",
    "segment_map = {'Low': 0, 'Medium': 1, 'High': 2, 'Recent': 2, 'Moderate': 1, 'Distant': 0}\n",
    "customer_segments['recency_score'] = customer_segments['recency_segment'].map(segment_map)\n",
    "customer_segments['frequency_score'] = customer_segments['frequency_segment'].map(segment_map)\n",
    "customer_segments['monetary_score'] = customer_segments['monetary_segment'].map(segment_map)\n",
    "customer_segments['rfm_score'] = customer_segments['recency_score'] + customer_segments['frequency_score'] + customer_segments['monetary_score']\n",
    "\n",
    "# Identify VIP customers and at-risk high-value customers\n",
    "customer_segments['segment'] = pd.cut(\n",
    "    customer_segments['rfm_score'],\n",
    "    bins=[0, 2, 4, 6],\n",
    "    labels=['Low Value', 'Medium Value', 'High Value']\n",
    ")\n",
    "\n",
    "print(\"\\n*** CUSTOMER SEGMENTATION ***\")\n",
    "print(customer_segments['segment'].value_counts())\n",
    "\n",
    "# Save for reporting\n",
    "customer_segments.to_csv('customer_segments.csv', index=False)\n",
    "\n",
    "# ## 10. Financial Impact Projections\n",
    "\n",
    "# Estimate financial impact of recommendations\n",
    "# 1. Cross-selling impact\n",
    "avg_order_value_current = avg_order_value\n",
    "potential_increase_pct = 0.15  # Estimated 15% increase from cross-selling\n",
    "potential_avg_order = avg_order_value_current * (1 + potential_increase_pct)\n",
    "annual_orders_estimate = total_orders * (12 / len(monthly_summary))  # Estimate annual orders\n",
    "potential_revenue_gain = (potential_avg_order - avg_order_value_current) * annual_orders_estimate\n",
    "\n",
    "# 2. Churn reduction impact\n",
    "high_value_churned = high_value_churn.shape[0]\n",
    "avg_high_value_spend = high_value_churn['total_spent'].mean()\n",
    "churn_recovery_rate = 0.3  # Assume we can recover 30% of high-value churned customers\n",
    "potential_churn_recovery = high_value_churned * churn_recovery_rate * avg_high_value_spend\n",
    "\n",
    "# Total potential financial impact\n",
    "total_potential_impact = potential_revenue_gain + potential_churn_recovery\n",
    "\n",
    "print(\"\\n*** FINANCIAL IMPACT PROJECTIONS ***\")\n",
    "print(f\"Potential Annual Revenue Gain from Cross-selling: ${potential_revenue_gain:,.2f}\")\n",
    "print(f\"Potential Revenue Recovery from Churn Reduction: ${potential_churn_recovery:,.2f}\")\n",
    "print(f\"Total Potential Financial Impact: ${total_potential_impact:,.2f}\")\n",
    "\n",
    "# ## 11. Implementation Roadmap\n",
    "\n",
    "print(\"\\n*** IMPLEMENTATION ROADMAP ***\")\n",
    "print(\"Phase 1 (Month 1-2): Data Integration and Dashboard Setup\")\n",
    "print(\"- Connect all data sources (ERP, Salesforce, ContaAzul)\")\n",
    "print(\"- Implement automated data pipelines\")\n",
    "print(\"- Create executive and operational dashboards\")\n",
    "print(\"\\nPhase 2 (Month 3-4): Customer Retention Program\")\n",
    "print(\"- Implement churn prediction model\")\n",
    "print(\"- Develop targeted retention campaigns for high-risk customers\")\n",
    "print(\"- Launch customer loyalty program\")\n",
    "print(\"\\nPhase 3 (Month 5-6): Revenue Optimization\")\n",
    "print(\"- Implement cross-selling recommendations in ordering system\")\n",
    "print(\"- Optimize product mix based on margin analysis\")\n",
    "print(\"- Personalize customer communications based on purchase history\")\n",
    "print(\"\\nPhase 4 (Month 7-8): Advanced Analytics\")\n",
    "print(\"- Implement predictive analytics for demand forecasting\")\n",
    "print(\"- Develop customer lifetime value projections\")\n",
    "print(\"- Create automated anomaly detection for business metrics\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
